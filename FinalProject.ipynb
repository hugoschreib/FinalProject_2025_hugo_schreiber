{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a665b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install pandas numpy scipy implicit scikit-learn surprise matplotlib networkx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31492d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fe0e69",
   "metadata": {},
   "source": [
    "## Import du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61bffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"data_final_project/KuaiRec 2.0/data\"\n",
    "\n",
    "df_inter = pd.read_csv(os.path.join(DATA_DIR, \"big_matrix.csv\"))\n",
    "\n",
    "df_cat = pd.read_csv(os.path.join(DATA_DIR, \"item_categories.csv\"))\n",
    "df_daily = pd.read_csv(os.path.join(DATA_DIR, \"item_daily_features.csv\"))\n",
    "df_user = pd.read_csv(os.path.join(DATA_DIR, \"user_features.csv\"))\n",
    "df_soc = pd.read_csv(os.path.join(DATA_DIR, \"social_network.csv\"))\n",
    "\n",
    "\n",
    "print(\"Interactions :\", df_inter.shape)\n",
    "print(\"Catégories :\",   df_cat.shape)\n",
    "print(\"Daily feat :\",   df_daily.shape)\n",
    "print(\"Social net :\",   df_soc.shape)\n",
    "print(\"User feat :\",    df_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3474aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_inter.head())\n",
    "display(df_cat.head())\n",
    "display(df_daily.head())\n",
    "display(df_soc.head())\n",
    "display(df_user.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab77c1fc",
   "metadata": {},
   "source": [
    "### Schéma des tables et relations\n",
    "\n",
    "Nous disposons de 5 DataFrames principaux :\n",
    "\n",
    "1. **`df_inter`** – historique des interactions utilisateur ↔ vidéo  \n",
    "   - Clé primaire implicite : couple `(user_id, video_id, timestamp)`  \n",
    "   - Champs clés :  \n",
    "     - `user_id` : identifiant de l’utilisateur  \n",
    "     - `video_id` : identifiant de la vidéo  \n",
    "     - `play_duration`, `video_duration`  \n",
    "     - `watch_ratio` = `play_duration / video_duration`  \n",
    "\n",
    "2. **`df_cat`** – catégories / attributs par vidéo  \n",
    "   - Clé primaire : `video_id`  \n",
    "   - `feat` : liste de catégories (p. ex. `[27, 9]`)  \n",
    "\n",
    "3. **`df_daily`** – statistiques journalières par vidéo  \n",
    "   - Clé unique : `(video_id, date)`  \n",
    "   - Ex. `play_cnt`, `like_cnt`, `share_cnt`, etc.  \n",
    "\n",
    "4. **`df_soc`** – relations sociales de chaque utilisateur  \n",
    "   - Clé primaire : `user_id`  \n",
    "   - `friend_list` : liste des IDs d’amis  \n",
    "\n",
    "5. **`df_user`** – profil et comportements des utilisateurs  \n",
    "   - Clé primaire : `user_id`  \n",
    "   - Champs descriptifs : `user_active_degree`, `follow_user_num`, `register_days`, plus one-hot features…  \n",
    "\n",
    "Les principales relations sont :  \n",
    "- `df_inter.user_id` → `df_user.user_id` (1:N)  \n",
    "- `df_inter.video_id` → `df_cat.video_id` (N:1)  \n",
    "- `df_inter.video_id` → `df_daily.video_id` (N:N via date)  \n",
    "- `df_user.user_id` → `df_soc.user_id` (1:1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f740064",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "G = nx.DiGraph()\n",
    "\n",
    "tables = [\"df_user\", \"df_soc\", \"df_inter\", \"df_cat\", \"df_daily\"]\n",
    "G.add_nodes_from(tables)\n",
    "\n",
    "edges = [\n",
    "    (\"df_inter\", \"df_user\"),   \n",
    "    (\"df_inter\", \"df_cat\"),    \n",
    "    (\"df_inter\", \"df_daily\"),  \n",
    "    (\"df_user\", \"df_soc\"),     \n",
    "]\n",
    "G.add_edges_from(edges)\n",
    "\n",
    "pos = {\n",
    "    \"df_user\":    (0, 1),\n",
    "    \"df_soc\":     (0, 0),\n",
    "    \"df_inter\":   (1, 0.5),\n",
    "    \"df_cat\":     (2, 1),\n",
    "    \"df_daily\":   (2, 0),\n",
    "}\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "nx.draw(G, pos, with_labels=True, node_size=2500, node_color=\"lightblue\", arrowsize=20)\n",
    "plt.title(\"Diagramme des tables et relations\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4737c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_daily['upload_type'] = df_daily['upload_type'].fillna('unknown')\n",
    "\n",
    "df_soc['friend_list'] = df_soc['friend_list'].fillna('').apply(lambda x: x.split(',') if x else [])\n",
    "\n",
    "num_cols = df_user.select_dtypes(include='number').columns\n",
    "for col in num_cols:\n",
    "    if df_user[col].isna().any():\n",
    "        median = df_user[col].median()\n",
    "        df_user[col].fillna(median, inplace=True)\n",
    "\n",
    "print(\"Valeurs manquantes restantes :\")\n",
    "for name, df in [('daily', df_daily), ('social', df_soc), ('user', df_user)]:\n",
    "    print(name, df.isna().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc47a4f",
   "metadata": {},
   "source": [
    "\n",
    "1. **`upload_type` → `'unknown'`**  \n",
    "   On remplace les valeurs manquantes par une catégorie explicite, pour éviter les erreurs lors des encodages ultérieurs.\n",
    "\n",
    "2. **`friend_list` → liste d’IDs**  \n",
    "   - On transforme d’abord les `NaN` en chaîne vide.  \n",
    "   - Puis on découpe chaque chaîne sur la virgule pour obtenir une liste d’identifiants, ou une liste vide si aucun ami.\n",
    "\n",
    "3. **Imputation médiane sur `df_user`**  \n",
    "   - On sélectionne toutes les colonnes numériques.  \n",
    "   - Pour chaque colonne ayant des `NaN`, on calcule sa médiane et on remplace les `NaN` par cette valeur, afin de conserver la distribution centrale sans être influencé par les outliers.\n",
    "\n",
    "4. **Vérification**  \n",
    "   - On totalise les `NaN` restants pour s’assurer qu’il n’en subsiste plus dans les tables traitées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92202d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter = df_inter.merge(\n",
    "    df_cat.rename(columns={'feat': 'video_category'}),\n",
    "    how='left', on='video_id'\n",
    ")\n",
    "\n",
    "print(\"Après fusion catégorie :\", df_inter.shape)\n",
    "print(df_inter[['video_id', 'video_category']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147a52a",
   "metadata": {},
   "source": [
    "\n",
    "1. **Renommage de colonne**  \n",
    "   On commence par renommer `feat` en `video_category` dans `df_cat` pour clarifier son rôle et éviter les ambiguïtés une fois fusionné.\n",
    "\n",
    "2. **Fusion (merge)**  \n",
    "   - `how='left'` : on réalise une jointure à gauche, c’est-à-dire que chaque ligne de `df_inter` est conservée, même si la vidéo n’a pas de catégorie associée dans `df_cat`.  \n",
    "   - `on='video_id'` : on s’appuie sur l’identifiant de la vidéo pour rattacher les catégories.\n",
    "\n",
    "3. **Vérification**  \n",
    "   - `df_inter.shape` affiche le nombre de lignes et de colonnes après la fusion (doit correspondre au nombre initial de lignes de `df_inter`, avec une colonne supplémentaire).  \n",
    "   - L’aperçu (`.head()`) montre que, pour chaque `video_id`, on dispose désormais de la liste `video_category` issue de `df_cat`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e722ea6",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2727b6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2a85e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inter['timestamp'] = pd.to_datetime(df_inter['timestamp'], unit='s')\n",
    "df_inter['date']      = df_inter['timestamp'].dt.date\n",
    "df_inter['hour']      = df_inter['timestamp'].dt.hour\n",
    "df_inter['dayofweek'] = df_inter['timestamp'].dt.dayofweek \n",
    "\n",
    "df_inter[['timestamp','date','hour','dayofweek']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80dc28b9",
   "metadata": {},
   "source": [
    "\n",
    "1. **`pd.to_datetime(..., unit='s')`**  \n",
    "   On convertit la colonne `timestamp` en objets `datetime64[ns]` de pandas, ce qui permet ensuite d’accéder à toutes ses composantes temporelles\n",
    "\n",
    "2. **`.dt.date`**  \n",
    "   L’attribut `dt.date` retourne uniquement la partie date (type `datetime.date`), sans information d’heure ni de fuseau\n",
    "\n",
    "3. **`.dt.hour`**  \n",
    "   L’attribut `dt.hour` extrait l’heure (entier de 0 à 23) de chaque timestamp, utile pour analyser les pics d’activité selon l’heure de la journée\n",
    "\n",
    "4. **`.dt.dayofweek`**  \n",
    "   L’attribut `dt.dayofweek` renvoie un entier de 0 (lundi) à 6 (dimanche), permettant d’étudier les variations journalières (weekend vs jours de semaine)\n",
    "\n",
    "Cette transformation enrichit `df_inter` de quatre nouvelles colonnes temporelles clés, ouvrant la voie à des analyses temporelles fines (saisonnalité horaire, comportements selon le jour de la semaine, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb78ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_agg = df_inter.groupby('user_id').agg(\n",
    "    user_total_views      = ('video_id','count'),\n",
    "    user_unique_videos    = ('video_id','nunique'),\n",
    "    user_mean_watch_ratio = ('watch_ratio','mean'),\n",
    "    user_std_watch_ratio  = ('watch_ratio','std')\n",
    ").reset_index()\n",
    "\n",
    "df_user = df_user.merge(user_agg, how='left', on='user_id')\n",
    "df_user[user_agg.columns] = df_user[user_agg.columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb5aec",
   "metadata": {},
   "source": [
    "\n",
    "1. **GroupBy + agg**  \n",
    "   - On regroupe `df_inter` par `user_id`.  \n",
    "   - Pour chaque utilisateur, on calcule quatre métriques :  \n",
    "     - **`user_total_views`** : nombre total d’enregistrements (vues).  \n",
    "     - **`user_unique_videos`** : nombre de vidéos distinctes visionnées.  \n",
    "     - **`user_mean_watch_ratio`** : ratio moyen de visionnage (`play_duration`/`video_duration`).  \n",
    "     - **`user_std_watch_ratio`** : dispersion de ces ratios (indicateur de régularité).\n",
    "\n",
    "2. **Fusion (`merge`)**  \n",
    "   - Avec `how='left'`, on ajoute ces nouvelles colonnes à `df_user`.  \n",
    "   - Les utilisateurs sans historique dans `df_inter` recevront des `NaN`.\n",
    "\n",
    "3. **Imputation des NaN par 0**  \n",
    "   - Pour tous les utilisateurs n’ayant pas d’interactions, on définit ces métriques à 0 (pas de vues, pas de diversité, etc.).\n",
    "\n",
    "4. **Résultat**  \n",
    "   - `df_user` est enrichi de quatre nouvelles fonctionnalités quantitatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6310cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_agg = df_inter.groupby('video_id').agg(\n",
    "    item_view_count       = ('user_id','count'),\n",
    "    item_unique_viewers   = ('user_id','nunique'),\n",
    "    item_mean_watch_ratio = ('watch_ratio','mean')\n",
    ").reset_index()\n",
    "\n",
    "df_cat = df_cat.merge(item_agg, how='left', on='video_id')\n",
    "df_cat[item_agg.columns] = df_cat[item_agg.columns].fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b19aa1a8",
   "metadata": {},
   "source": [
    "1. **GroupBy + agg**  \n",
    "   - On regroupe `df_inter` par `video_id`.  \n",
    "   - Pour chaque vidéo, on calcule trois métriques :  \n",
    "     - **`item_view_count`** : nombre total de vues (tous utilisateurs confondus).  \n",
    "     - **`item_unique_viewers`** : nombre d’utilisateurs distincts ayant visionné la vidéo.  \n",
    "     - **`item_mean_watch_ratio`** : ratio moyen de visionnage, indicateur de la rétention moyenne.\n",
    "\n",
    "2. **Fusion (`merge`)**  \n",
    "   - Avec `how='left'`, on ajoute ces colonnes à `df_cat` tout en conservant toutes les vidéos existantes.  \n",
    "   - Si une vidéo n’apparaît pas dans `df_inter`, elle recevra un `NaN` pour ces métriques.\n",
    "\n",
    "3. **Imputation des NaN par 0**  \n",
    "   - Pour les vidéos sans aucune interaction, on fixe ces métriques à 0 (aucune vue, aucun spectateur, ratio de visionnage nul).\n",
    "\n",
    "4. **Résultat**  \n",
    "   - `df_cat` est désormais enrichi de trois nouvelles fonctionnalités descriptives, prêtes à être utilisées pour l’entraînement ou l’analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be96955",
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_plays = df_inter.groupby(['video_id','date']).size().reset_index(name='plays')\n",
    "daily_plays['date'] = pd.to_datetime(daily_plays['date'])\n",
    "\n",
    "daily_plays = daily_plays.sort_values(['video_id','date'])\n",
    "daily_plays['plays_7d'] = daily_plays.groupby('video_id')['plays']\\\n",
    "                                     .transform(lambda x: x.rolling(7, min_periods=1).sum())\n",
    "\n",
    "df_daily['date'] = pd.to_datetime(df_daily['date'])\n",
    "daily_plays['date'] = pd.to_datetime(daily_plays['date'])\n",
    "\n",
    "df_daily = df_daily.merge(\n",
    "    daily_plays[['video_id','date','plays_7d']],\n",
    "    how='left',\n",
    "    on=['video_id','date']\n",
    ")\n",
    "\n",
    "df_daily['plays_7d'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819711d1",
   "metadata": {},
   "source": [
    "1. **Agrégation journalière (`groupby` + `size`)**  \n",
    "   On commence par compter, pour chaque couple `(video_id, date)`, le nombre d’enregistrements dans `df_inter`. Ce comptage représente le nombre total de lectures de la vidéo ce jour-là.\n",
    "\n",
    "2. **Conversion en `datetime`**  \n",
    "   Pour pouvoir trier et appliquer une fenêtre glissante sur une colonne de dates, il faut travailler avec le type `datetime64[ns]`.\n",
    "\n",
    "3. **Tri chronologique**  \n",
    "   Le tri par `(video_id, date)` garantit que, lors de l’application de la fenêtre glissante, les lectures sont correctement ordonnées du plus ancien au plus récent.\n",
    "\n",
    "4. **Fenêtre glissante de 7 observations**  \n",
    "   - `groupby('video_id')['plays']` : on cible la série des lectures pour chaque vidéo séparément.  \n",
    "   - `.transform(lambda x: x.rolling(7, min_periods=1).sum())` :  \n",
    "     - La méthode `rolling(window, min_periods)` crée une **fenêtre glissante** de largeur fixe (ici 7 lignes).  \n",
    "     - `min_periods=1` permet d’obtenir une valeur même si moins de 7 jours sont disponibles (utile pour les premières dates).  \n",
    "     - La somme de la fenêtre donne, pour chaque date, le total des lectures des 7 derniers jours.\n",
    "\n",
    "5. **Fusion des données**  \n",
    "   On rattache la colonne `plays_7d` à `df_daily` via une jointure gauche (`how='left'`) sur `video_id` et `date`. Cela ajoute la métrique à chaque ligne de `df_daily`.\n",
    "\n",
    "6. **Imputation finale**  \n",
    "   Pour les vidéos ou dates n’apparaissant pas dans `daily_plays` (par exemple, moins d’une semaine de données), `plays_7d` sera `NaN` après la fusion : on remplace ces valeurs par 0, signifiant « aucune lecture sur la période ».\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029440a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "cat_ohe = ohe.fit_transform(df_cat[['feat']])\n",
    "cat_ohe = pd.DataFrame(cat_ohe, columns=[f\"cat_{c}\" for c in ohe.categories_[0]])\n",
    "df_cat = pd.concat([df_cat.reset_index(drop=True), cat_ohe], axis=1)\n",
    "\n",
    "vect = CountVectorizer(token_pattern=r\"(?u)\\b\\w+\\b\", min_df=10)\n",
    "tag_sparse = vect.fit_transform(df_daily['video_tag_name'].fillna(''))\n",
    "\n",
    "tags_df = pd.DataFrame.sparse.from_spmatrix(tag_sparse, \n",
    "             index=df_daily.index, columns=[f\"tag_{t}\" for t in vect.get_feature_names_out()])\n",
    "df_daily = pd.concat([df_daily, tags_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61e87ab",
   "metadata": {},
   "source": [
    "- **OneHotEncoder** : on instancie `OneHotEncoder` de scikit‑learn avec `sparse_output=False` pour obtenir un tableau dense (au lieu d’une matrice creuse).  \n",
    "- **fit_transform(df_cat[['feat']])** : la méthode `fit_transform` apprend sur la colonne `feat` (liste d’identifiants de catégories) et renvoie une matrice de 0/1 indiquant la présence de chaque catégorie pour chaque vidéo.  \n",
    "- **Construction de `cat_ohe`** : on convertit la matrice numpy en DataFrame pandas, en nommant les colonnes comme `cat_{c}` pour chaque catégorie `c` identifiée par l’encodeur.  \n",
    "- **Concaténation** : `pd.concat([...], axis=1)` fusionne horizontalement `df_cat` et `cat_ohe`, ajoutant autant de nouvelles colonnes binaires que de catégories uniques.  \n",
    "\n",
    "- **CountVectorizer** : instancié avec `token_pattern=r\"(?u)\\b\\w+\\b\"` pour capturer chaque mot (même d’un seul caractère) et `min_df=10` pour ne conserver que les tokens présents dans au moins 10 documents, filtrant ainsi le bruit.  \n",
    "- **fillna('')** : on remplace les `NaN` de `video_tag_name` par chaîne vide afin que `CountVectorizer` ne plante pas sur valeurs manquantes.  \n",
    "- **fit_transform** : génère un objet `scipy.sparse.csr_matrix` de comptages de tokens par ligne (une ligne = une vidéo/jour).  \n",
    "- **from_spmatrix** : `pd.DataFrame.sparse.from_spmatrix` convertit la matrice creuse en DataFrame pandas à colonnes creuses (`SparseArray`), économisant de la mémoire quand la majorité des compteurs est nulle.  \n",
    "- **naming** : chaque colonne de tags est préfixée par `tag_{t}` pour chaque token `t` du vocabulaire appris, facilitant l’identification dans le DataFrame.  \n",
    "- **Concaténation finale** : on rassemble `df_daily` et `tags_df` pour enrichir les données journalières de features textuelles exploitables en apprentissage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d151090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "user_ids = df_inter['user_id'].unique()\n",
    "item_ids = df_inter['video_id'].unique()\n",
    "uid2idx = {u:i for i,u in enumerate(user_ids)}\n",
    "iid2idx = {i:j for j,i in enumerate(item_ids)}\n",
    "\n",
    "rows = df_inter['user_id'].map(uid2idx)\n",
    "cols = df_inter['video_id'].map(iid2idx)\n",
    "data = df_inter['watch_ratio'].values\n",
    "\n",
    "R = sp.csr_matrix((data, (rows, cols)), shape=(len(user_ids), len(item_ids)))\n",
    "print(\"Sparse matrix R shape:\", R.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd45173",
   "metadata": {},
   "source": [
    "1. **Extraction des identifiants uniques**  \n",
    "   - `user_ids` et `item_ids` contiennent respectivement tous les `user_id` et `video_id` distincts présents dans `df_inter`.  \n",
    "   - Cela fixe les dimensions de la matrice (nombre d’utilisateurs × nombre de vidéos).\n",
    "\n",
    "2. **Création des dictionnaires de mapping**  \n",
    "   - `uid2idx` associe chaque `user_id` à un index de 0 à `n_users − 1`.  \n",
    "   - `iid2idx` fait de même pour chaque `video_id`, de 0 à `n_items − 1`.  \n",
    "   - Ces mappings servent à positionner correctement chaque interaction dans la matrice.\n",
    "\n",
    "3. **Génération des vecteurs `rows` et `cols`**  \n",
    "   - On transforme la colonne `user_id` en indices de lignes avec `.map(uid2idx)`,  \n",
    "   - et la colonne `video_id` en indices de colonnes avec `.map(iid2idx)`.\n",
    "\n",
    "4. **Récupération des valeurs**  \n",
    "   - `data` contient la liste des `watch_ratio` correspondant à chaque interaction (i.e., chaque ligne de `df_inter`).\n",
    "\n",
    "5. **Construction de la CSR (Compressed Sparse Row)**  \n",
    "   - `sp.csr_matrix((data, (rows, cols)), shape=(n_users, n_items))` crée une matrice creuse où  \n",
    "     - `data[i]` est placé en position `(rows[i], cols[i])`.  \n",
    "   - CSR est efficace en mémoire pour stocker des matrices majoritairement nulles (ici, la plupart des \"utilisateur‑vidéo\" n’ont pas d’interaction).\n",
    "\n",
    "La matrice `R` peut désormais être utilisée en entrée pour des algorithmes de factorisation, comme la SVD ou l’ALS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b6817d6",
   "metadata": {},
   "source": [
    "## Model developpement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ef1abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit                       \n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import csr_matrix\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60d1b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "idx = np.arange(df_inter.shape[0])\n",
    "train_idx, test_idx = train_test_split(idx, test_size=0.2, random_state=42)\n",
    "\n",
    "df_train = df_inter.iloc[train_idx].reset_index(drop=True)\n",
    "df_test  = df_inter.iloc[test_idx].reset_index(drop=True)\n",
    "\n",
    "def build_sparse(df):\n",
    "    rows = df['user_id'].map(uid2idx)\n",
    "    cols = df['video_id'].map(iid2idx)\n",
    "    data = df['watch_ratio'].values\n",
    "    return csr_matrix((data, (rows, cols)), shape=R.shape)\n",
    "\n",
    "R_train = build_sparse(df_train)\n",
    "R_test  = build_sparse(df_test)\n",
    "\n",
    "print(\"Train matrix shape:\", R_train.shape)\n",
    "print(\"Test matrix shape :\", R_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c55174",
   "metadata": {},
   "source": [
    "1. **Séparation train/test**  \n",
    "   - On génère un index de toutes les lignes (`idx`).  \n",
    "   - `train_test_split(..., test_size=0.2)` choisit 20 % des indices pour le test, 80 % pour l’entraînement, avec une graine (`random_state=42`) pour reproductibilité.\n",
    "\n",
    "2. **Découpage des DataFrames**  \n",
    "   - `df_inter.iloc[train_idx]` et `df_inter.iloc[test_idx]` isolent les interactions de chaque sous-ensemble.\n",
    "\n",
    "3. **Fonction `build_sparse`**  \n",
    "   - Reprend la même logique que pour `R` : conversion des `user_id` et `video_id` en indices puis assemblage d’une matrice CSR, avec la forme `(n_users, n_items)` identique à `R`.\n",
    "\n",
    "4. **Matrices `R_train` et `R_test`**  \n",
    "   - `R_train` contient les ratios de visionnage pour les interactions d’entraînement.  \n",
    "   - `R_test` contient ceux du test, prêts pour évaluer la qualité du modèle.\n",
    "\n",
    "5. **Validation**  \n",
    "   - L’affichage des shapes confirme que la taille des matrices reste `(nombre_utilisateurs, nombre_vidéos)`, mais les données diffèrent selon train/test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d500c429",
   "metadata": {},
   "source": [
    "### Modele ALS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccf11a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import implicit\n",
    "\n",
    "model_als = implicit.als.AlternatingLeastSquares(\n",
    "    factors=50,\n",
    "    regularization=0.1,\n",
    "    iterations=20,\n",
    "    use_gpu=False\n",
    ")\n",
    "\n",
    "\n",
    "model_als.fit(R_train)\n",
    "\n",
    "\n",
    "user    = df_train['user_id'].unique()[0]\n",
    "uidx    = uid2idx[user]\n",
    "\n",
    "user_items = R_train[uidx, :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfdfb450",
   "metadata": {},
   "source": [
    "1. **AlternatingLeastSquares**  \n",
    "   - Ce modèle factorise la matrice creuse en deux matrices latentes, une pour les items et une pour les users, en résolvant alternativement un système de moindres carrés pour l’un puis l’autre.  \n",
    "   - Les **`factors`** définissent la dimensionnalité des vecteurs latents,  \n",
    "   - **`regularization`** pénalise les poids importants pour mieux généraliser,  \n",
    "   - **`iterations`** contrôle la convergence par itération.\n",
    "\n",
    "2. **Entraînement (`fit`)**  \n",
    "   - On fournit `R_train`, où chaque ligne correspond à un utilisateur et chaque colonne à une vidéo, avec pour valeur le `watch_ratio`.  \n",
    "   - Le calcul peut exiger une matrice transposée (`item × user`), mais la bibliothèque `implicit` gère cela en interne.\n",
    "\n",
    "3. **Choix d’un utilisateur**  \n",
    "   - Pour illustrer, on récupère le premier `user_id` du jeu d’entraînement, puis on le mapppe à son index `uidx`.  \n",
    "   - Cela permettra de générer des recommandations spécifiques à cet utilisateur.\n",
    "\n",
    "4. **Extraction des interactions existantes**  \n",
    "   - `user_items = R_train[uidx, :]` renvoie un vecteur creux où chaque entrée non nulle indique un `watch_ratio` pour une vidéo déjà vue.  \n",
    "   - On peut utiliser ce vecteur pour masquer ces items lors de la génération de recommandations ou pour analyser le comportement passé de l’utilisateur.\n",
    "\n",
    "> À la suite de cette préparation, on pourra appeler `model_als.recommend(uidx, user_items, N=10)` pour obtenir les 10 meilleures recommandations pour cet utilisateur, en excluant les vidéos déjà vues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac68b6a9",
   "metadata": {},
   "source": [
    " ### Modele SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9637543",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "import numpy as np\n",
    "\n",
    "n_factors = 20\n",
    "\n",
    "\n",
    "svd = TruncatedSVD(n_components=n_factors, random_state=42)\n",
    "\n",
    "U = svd.fit_transform(R_train)      \n",
    "Sigma = svd.singular_values_        \n",
    "Vt = svd.components_                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14168b7d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **`n_components=20`**  \n",
    "   On choisit de projeter notre matrice utilisateur–vidéo dans un espace latent de dimension 20. Ce paramètre représente la complexité du modèle :  \n",
    "   - Trop petit → perte d’information.  \n",
    "   - Trop grand → risque de surapprentissage.\n",
    "\n",
    "2. **`TruncatedSVD`**  \n",
    "   - Semblable à la SVD classique, mais optimisé pour les matrices creuses et de grande dimension.  \n",
    "   - Ne centre pas les données ; si nécessaire, il faut d’abord **centrer** la matrice (soustraction de la moyenne par utilisateur ou par item).\n",
    "\n",
    "3. **`fit_transform(R_train)` → `U`**  \n",
    "   - Calcule les vecteurs propres associés aux 20 premiers vecteurs singuliers.  \n",
    "   - Renvoie la matrice **U** de dimension `(n_users, 20)` contenant l’“embedding” de chaque utilisateur.\n",
    "\n",
    "4. **`singular_values_` → `Sigma`**  \n",
    "   - Tableau des 20 valeurs singulières décroissantes, illustrant l’importance de chaque facteur latent.\n",
    "\n",
    "5. **`components_` → `Vt`**  \n",
    "   - Matrice de dimension `(20, n_items)` où chaque colonne est l’“embedding” d’une vidéo dans l’espace latent.\n",
    "\n",
    "> **Utilisation ultérieure** :  \n",
    "> Pour prédire un score pour l’utilisateur *u* et la vidéo *i*, on calcule le produit scalaire\n",
    "> ce qui permet de générer des recommandations en triant ces scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb190fd",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ddb5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_svd(user_id, U, Vt, uid2idx, item_ids, N=10):\n",
    " \n",
    "    uidx = uid2idx[user_id]\n",
    "    user_vec = U[uidx]               \n",
    "    scores = user_vec.dot(Vt)         \n",
    "    top_idx = np.argsort(-scores)[:N]\n",
    "    return [int(item_ids[i]) for i in top_idx]\n",
    "\n",
    "user = df_train['user_id'].unique()[0]\n",
    "top10_svd = recommend_svd(user, U, Vt, uid2idx, item_ids, N=10)\n",
    "print(f\"Top 10 SVD pour user {user} : {top10_svd}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0bd04e",
   "metadata": {},
   "source": [
    "\n",
    "1. **Mapping utilisateur → index**  \n",
    "   La fonction utilise `uid2idx` pour retrouver la ligne de la matrice **U** correspondant à `user_id`.\n",
    "\n",
    "2. **Embeddings utilisateur**  \n",
    "   `user_vec` est un vecteur de dimension `n_factors` représentant les préférences latentes de l’utilisateur.\n",
    "\n",
    "3. **Calcul des scores**  \n",
    "   Pour chaque vidéo, on calcule le produit scalaire entre `user_vec` et la colonne correspondante de **Vt**.  \n",
    "   \\[\n",
    "     \\text{score}_{u,i} = U_{u,:} \\times Vt_{:,i}\n",
    "   \\]\n",
    "\n",
    "4. **Tri et sélection**  \n",
    "   - `np.argsort(-scores)` trie les scores par ordre décroissant.  \n",
    "   - On prend les `N` premières positions pour obtenir les indices des meilleures vidéos.\n",
    "\n",
    "5. **Récupération des IDs**  \n",
    "   Enfin, on convertit ces indices en `video_id` originaux via la liste `item_ids` et on renvoie la liste finale.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e80ed9d",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893c0263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def evaluate_als(model, R_train, df_test, uid2idx, item_ids, K=10):\n",
    "    \"\"\"\n",
    "    Évalue un modèle ALS entraîné sur R_train (user×item).\n",
    "    - model      : instance de AlternatingLeastSquares déjà fit()\n",
    "    - R_train    : csr_matrix (n_users, n_items)\n",
    "    - df_test    : DataFrame test avec colonnes ['user_id','video_id']\n",
    "    - uid2idx    : dict mapping user_id → index\n",
    "    - item_ids   : array-like index → video_id\n",
    "    - K          : cutoff pour Precision@K, Recall@K\n",
    "    \"\"\"\n",
    "    n_users, n_items = R_train.shape\n",
    "\n",
    "    rows = df_test['user_id'].map(uid2idx)\n",
    "    cols = df_test['video_id'].map({v:i for i,v in enumerate(item_ids)})\n",
    "    data = np.ones(len(df_test), dtype=np.int8)\n",
    "    R_test = csr_matrix((data, (rows, cols)), shape=(n_users, n_items))\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    R_train = R_train.tocsr()\n",
    "    R_test  = R_test.tocsr()\n",
    "\n",
    "\n",
    "    for user_id in df_test['user_id'].unique():\n",
    "        uidx = uid2idx.get(user_id)\n",
    "        if uidx is None:\n",
    "            continue\n",
    "\n",
    "        train_vec = R_train[uidx, :]\n",
    "        true_vec = R_test[uidx, :]\n",
    "        true_items = set(true_vec.indices)\n",
    "        if not true_items:\n",
    "            continue\n",
    "\n",
    "        recs_idx, _ = model.recommend(\n",
    "            userid=uidx,\n",
    "            user_items=train_vec,\n",
    "            N=K,\n",
    "            filter_already_liked_items=True\n",
    "        )\n",
    "        rec_items = set(recs_idx)\n",
    "\n",
    "        hits = rec_items & true_items\n",
    "        recall    = len(hits) / len(true_items)\n",
    "        precision = len(hits) / K\n",
    "\n",
    "        recalls.append(recall)\n",
    "        precisions.append(precision)\n",
    "\n",
    "    return {\n",
    "        'Recall@K': np.mean(recalls),\n",
    "        'Precision@K': np.mean(precisions)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa91931",
   "metadata": {},
   "source": [
    "1. **Construction de `R_test`**  \n",
    "   On crée, à partir de `df_test`, une matrice creuse binaire de même forme que `R_train` où chaque entrée vaut 1 si l’utilisateur a réellement interagi avec la vidéo dans le jeu de test.\n",
    "\n",
    "2. **Itération par utilisateur**  \n",
    "   Pour chaque `user_id` du test, on récupère :\n",
    "   - `train_vec` : le vecteur des interactions d’entraînement (pour masquer les items déjà vus),\n",
    "   - `true_vec` : le vecteur binaire des interactions test (pour calculer le rappel).\n",
    "\n",
    "3. **Recommandation ALS**  \n",
    "   Avec `model.recommend`, on demande les `K` vidéos les mieux prédites tout en filtrant celles déjà vues en entraînement.\n",
    "\n",
    "4. **Calcul des métriques**  \n",
    "   - **Hits** : intersection entre recommandations et véritables items test.  \n",
    "   - **Recall@K** : proportion des items test retrouvés dans les recommandations.  \n",
    "   - **Precision@K** : proportion des recommandations qui étaient réellement pertinentes.\n",
    "\n",
    "5. **Agrégation finale**  \n",
    "   On renvoie la moyenne de la précision et du rappel sur tous les utilisateurs testés, ce qui donne une évaluation globale du modèle ALS.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5326064",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluate_als(\n",
    "    model     = model_als,\n",
    "    R_train   = R_train,\n",
    "    df_test   = df_test[['user_id','video_id']],\n",
    "    uid2idx   = uid2idx,\n",
    "    item_ids  = item_ids,\n",
    "    K         = 10\n",
    ")\n",
    "\n",
    "print(f\"ALS - Recall@10    : {results['Recall@K']:.4f}\")\n",
    "print(f\"ALS - Precision@10 : {results['Precision@K']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef84ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_svd(U, Vt, uid2idx, item_ids, df_test, k=10):\n",
    "   \n",
    "    from collections import defaultdict\n",
    "\n",
    "    itemid2idx = {v: i for i, v in enumerate(item_ids)}\n",
    "\n",
    "    user_to_items_test = df_test.groupby('user_id')['video_id'].apply(set).to_dict()\n",
    "\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "\n",
    "    for user_id in user_to_items_test:\n",
    "        if user_id not in uid2idx:\n",
    "            continue  \n",
    "\n",
    "        try:\n",
    "            top_k_pred = recommend_svd(user_id, U, Vt, uid2idx, item_ids, N=k)\n",
    "        except KeyError:\n",
    "            continue  \n",
    "\n",
    "        true_items = user_to_items_test[user_id]\n",
    "\n",
    "        tp = len(set(top_k_pred) & true_items)\n",
    "\n",
    "        precision = tp / k\n",
    "        recall = tp / len(true_items) if true_items else 0\n",
    "\n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "\n",
    "    avg_precision = np.mean(precisions)\n",
    "    avg_recall = np.mean(recalls)\n",
    "\n",
    "    print(f\"Average Precision@{k} for SVD: {avg_precision:.4f}\")\n",
    "    print(f\"Average Recall@{k} for SVD: {avg_recall:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_svd(U, Vt, uid2idx, item_ids, df_test, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac11471e",
   "metadata": {},
   "source": [
    "1. **Mapping inverse des items**  \n",
    "   On crée `itemid2idx` pour convertir chaque `video_id` en son index, mais ici il n’est finalement pas utilisé directement dans le calcul — l’essentiel est de pouvoir extraire les vrais items test du DataFrame.\n",
    "\n",
    "2. **Rassemblement des véritables items (`user_to_items_test`)**  \n",
    "   Grâce à `groupby` + `apply(set)`, on obtient pour chaque `user_id` un ensemble (`set`) des vidéos réellement visionnées dans le jeu de test.\n",
    "\n",
    "3. **Parcours des utilisateurs**  \n",
    "   On itère sur chaque utilisateur présent dans `user_to_items_test`. Si l’utilisateur n’existe pas dans le mapping `uid2idx`, on l’ignore (cas cold‑start).\n",
    "\n",
    "4. **Génération des prédictions SVD**  \n",
    "   On appelle `recommend_svd`, qui retourne les `k` vidéos les mieux notées pour cet utilisateur, selon le produit scalaire entre son embedding (`U`) et les embeddings des vidéos (`Vt`).\n",
    "\n",
    "5. **Calcul des vraies positives (`tp`)**  \n",
    "   On mesure l’intersection entre les prédictions (`top_k_pred`) et l’ensemble des vidéos test (`true_items`).\n",
    "\n",
    "6. **Précision et rappel**  \n",
    "   - **Precision@K** = `tp / k`  \n",
    "   - **Recall@K** = `tp / |true_items|` (avec garde-fou `if true_items else 0` pour éviter la division par zéro)\n",
    "\n",
    "7. **Moyenne globale**  \n",
    "   On agrège les métriques sur tous les utilisateurs et on affiche les résultats finaux pour évaluer la qualité du modèle SVD.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39bca53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in [10, 20, 50, 100]:\n",
    "    svd = TruncatedSVD(n_components=n, random_state=42)\n",
    "    U = svd.fit_transform(R_train)\n",
    "    Vt = svd.components_\n",
    "    print(f\"\\n-- Factors: {n} --\")\n",
    "    evaluate_svd(U, Vt, uid2idx, item_ids, df_test, k=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c79598f",
   "metadata": {},
   "source": [
    "#### Bonus\n",
    "\n",
    "A partir de cette boucle, on essaye de rouver le meilleur paramètre de composants pour notre SVD en se basant sur la précision et le rappel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82c6f3",
   "metadata": {},
   "source": [
    "## Analyse des résultats de recommandation\n",
    "\n",
    "- **SVD (TruncatedSVD)**  \n",
    "  - *Precision@10* = 0.1590  \n",
    "  - *Recall@10*    = 0.0077  \n",
    "  \n",
    "  La précision faible (≈16 %) indique que, parmi les 10 items recommandés à chaque utilisateur, seuls 1 à 2 sont en moyenne effectivement pertinents. Le rappel quasi nul (<1 %) révèle que le modèle SVD ne couvre quasiment aucune des vidéos réellement regardées par l’utilisateur dans le jeu de test. Cela suggère que les vecteurs latents extraits par SVD sont trop généraux ou mal adaptés aux préférences fines des utilisateurs (sous‑apprentissage ou mauvaise captation des signaux faibles).\n",
    "\n",
    "- **ALS (Alternating Least Squares)**  \n",
    "  - *Precision@10* = 0.6715  \n",
    "  - *Recall@10*    = 0.0272  \n",
    "  \n",
    "  Avec près de 67 % de précision, l’ALS propose majoritairement des recommandations pertinentes. Cependant, son rappel reste faible (~2.7 %), ce qui signifie que, bien qu’il “touche juste” quand il recommande, il ne couvre toujours qu’une très petite fraction des vidéos réellement vues.  \n",
    "\n",
    "### Ce qu'on peut en déduire\n",
    "\n",
    "1. **Couverture vs. exactitude**  \n",
    "   - ALS privilégie la “sécurité” : il recommande moins d’items différents (faible rappel) mais quasiment toujours pertinents (haute précision).  \n",
    "   - SVD, en revanche, disperse ses recommandations dans tout l’espace latent, capturant un peu plus de diversité mais perd en exactitude et passe à côté de presque tous les items pertinents.\n",
    "\n",
    "2. **Influence du format des données**  \n",
    "   - ALS est spécifiquement conçu pour les matrices creuses d’implicite (watch_ratio), avec régularisation adaptative, et se montre mieux calibré sur des interactions binaires/pondérées.  \n",
    "   - SVD linéaire « brut » sur ces mêmes données peut souffrir d’un manque de centrage ou de traitement du biais utilisateur/item.\n",
    "\n",
    "3. **Axes d’amélioration**  \n",
    "   - **Pour SVD** :  \n",
    "     - Centrage (soustraction de la moyenne par user/item) avant factorisation.  \n",
    "     - Ajustement de `n_components` (réduction ou augmentation des facteurs).  \n",
    "     - Ajout de pondération ou de normalisation (TF-IDF, BM25) sur les interactions.  \n",
    "   - **Pour ALS** :  \n",
    "     - Exploration de la régularisation et du nombre d’itérations.  \n",
    "     - Validation croisée pour optimiser `factors`, `regularization`.  \n",
    "     - Hybridation avec des features utilisateur/item (métadonnées, tags, catégories) pour augmenter le rappel.\n",
    "\n",
    "> **Conclusion** : l’ALS l’emporte nettement en précision, mais tous deux montrent un rappel très bas, typique des systèmes de recommandation sur données très creuses. Pour monter en performance globale, il faudra combiner ces approches avec des signaux non implicites et du filtrage hybrides.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
